{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHg/2nxE7eUPxFiWkFXcno",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjanb/Machine-Learning-basics/blob/main/NeurakNetwork_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is this code doing?**\n",
        "This code is building and training a **neural network** to recognize handwritten digits (0-9) from the **MNIST dataset**, which contains images of handwritten digits.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step-by-step explanation**\n",
        "\n",
        "#### **1. Loading the MNIST Dataset**\n",
        "```python\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "```\n",
        "- The MNIST dataset contains 60,000 training images and 10,000 testing images of handwritten digits (0-9).\n",
        "- Each image is 28x28 pixels in grayscale.\n",
        "- `transforms.ToTensor()` converts the images into PyTorch tensors (a format PyTorch can work with).\n",
        "- `transforms.Normalize((0.5,), (0.5,))` adjusts the pixel values to be between -1 and 1 for better training performance.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Creating Data Loaders**\n",
        "```python\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "```\n",
        "- A **DataLoader** helps us load the data in small batches (e.g., 64 images at a time) instead of all at once.\n",
        "- `shuffle=True` means the training data is shuffled randomly before each epoch (one full pass through the dataset).\n",
        "- `shuffle=False` for the test data ensures we evaluate the model on the same order every time.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Defining the Neural Network**\n",
        "```python\n",
        "class NeuralNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "    self.fc2 = torch.nn.Linear(128, 64)\n",
        "    self.fc3 = torch.nn.Linear(64, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "```\n",
        "- This defines a simple neural network with three layers:\n",
        "  - **Input Layer**: Takes a flattened version of the 28x28 image (784 pixels).\n",
        "  - **Hidden Layers**: Two fully connected (dense) layers with 128 and 64 neurons, respectively. These use the **ReLU activation function** to introduce non-linearity.\n",
        "  - **Output Layer**: Outputs 10 values (one for each digit: 0-9). These represent the \"confidence\" that the input image belongs to each digit.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Creating the Model, Loss Function, and Optimizer**\n",
        "```python\n",
        "model = NeuralNet()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "```\n",
        "- `model = NeuralNet()` creates an instance of the neural network.\n",
        "- `criterion = torch.nn.CrossEntropyLoss()` defines the loss function, which measures how wrong the model's predictions are compared to the true labels.\n",
        "- `optimizer = torch.optim.Adam(...)` sets up the optimizer, which adjusts the model's weights during training to minimize the loss.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Training the Model**\n",
        "```python\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()  # Reset gradients\n",
        "    outputs = model(images)  # Forward pass (predict)\n",
        "    loss = criterion(outputs, labels)  # Compute loss\n",
        "    loss.backward()  # Backward pass (compute gradients)\n",
        "    optimizer.step()  # Update weights\n",
        "  print(f\"epoch {epoch+1}, Loss:{loss.item()}\")\n",
        "```\n",
        "- The model is trained for 10 epochs (10 full passes through the training data).\n",
        "- For each batch of images:\n",
        "  1. The model makes predictions (`outputs`).\n",
        "  2. The loss is calculated by comparing predictions to the true labels.\n",
        "  3. Gradients are computed using backpropagation (`loss.backward()`).\n",
        "  4. The optimizer updates the model's weights to reduce the loss (`optimizer.step()`).\n",
        "- After each epoch, the current loss is printed to track progress.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Evaluating the Model**\n",
        "```python\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print(f\"Accuracy on the test set: {100 * correct / total}%\")\n",
        "```\n",
        "- After training, the model is tested on the unseen test dataset to evaluate its performance.\n",
        "- For each batch of test images:\n",
        "  1. The model predicts the digit (`outputs`).\n",
        "  2. The predicted digit is compared to the true label.\n",
        "  3. Correct predictions are counted.\n",
        "- Finally, the accuracy (percentage of correct predictions) is printed.\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "1. **Dataset**: Loads handwritten digit images (MNIST).\n",
        "2. **Model**: Builds a simple neural network with three layers.\n",
        "3. **Training**: Trains the model using the training data and adjusts weights to minimize prediction errors.\n",
        "4. **Testing**: Evaluates the model on unseen test data to measure its accuracy.\n",
        "\n",
        "By the end, the model should be able to recognize handwritten digits with reasonable accuracy (e.g., ~95% or higher)."
      ],
      "metadata": {
        "id": "mc8ln3pBr53m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja-QGAImb2vY",
        "outputId": "0d9272b9-62c3-4ade-dd1f-dabcb8987f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 52.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.88MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.28MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "epoch 1, Loss:0.24933141469955444\n",
            "epoch 2, Loss:0.0605836920440197\n",
            "epoch 3, Loss:0.20769014954566956\n",
            "epoch 4, Loss:0.0070379069074988365\n",
            "epoch 5, Loss:0.17141886055469513\n",
            "epoch 6, Loss:0.00596141442656517\n",
            "epoch 7, Loss:0.03204083815217018\n",
            "epoch 8, Loss:0.028609707951545715\n",
            "epoch 9, Loss:0.11041945964097977\n",
            "epoch 10, Loss:0.0026470590382814407\n",
            "Accuracy on the test set: 96.78%\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define a neural network\n",
        "class NeuralNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "    self.fc2 = torch.nn.Linear(128, 64)\n",
        "    self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "# The issue was on this line, it should be an assignment (=), not a subtraction (-)\n",
        "model = NeuralNet()\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"epoch {epoch+1}, Loss:{loss.item()}\")\n",
        "\n",
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test set: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'mnist_model.pth')\n",
        "print(\"Wodel saved!!\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = NeuralNet()\n",
        "loaded_model.load_state_dict(torch.load('mnist_model.pth')) # Correctly load the state dict\n",
        "print(\"Model loaded!!\")\n",
        "\n",
        "\n",
        "# make the predictions\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "    images, labels = batch\n",
        "    output = loaded_model(images)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    print(\"Predictions:\", predicted[:10])\n",
        "    print(\"Actual:\", labels[:10])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIxsAoA5tR8X",
        "outputId": "aef069bc-0e5d-4253-d9bf-82e4361dcdf3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wodel saved!!\n",
            "Model loaded!!\n",
            "Predictions: tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n",
            "Actual: tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4e6b9688dc6b>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load('mnist_model.pth')) # Correctly load the state dict\n"
          ]
        }
      ]
    }
  ]
}
